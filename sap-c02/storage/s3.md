# Amazon S3 (Simple Storage Service)

## What is S3?

Amazon S3 is object storage built to store and retrieve any amount of data from anywhere on the internet. It's designed for 99.999999999% (11 9's) durability and 99.99% availability. Think of it as an infinite, highly durable file system accessible via HTTP/HTTPS.

## Why Use S3?

### Key Benefits
- **Durability**: 99.999999999% (11 9's) - if you store 10 million objects, expect to lose 1 object every 10,000 years
- **Availability**: 99.99% (Standard) - 52.56 minutes downtime per year
- **Scalability**: Unlimited storage, single object up to 5 TB
- **Performance**: 3,500 PUT/POST/DELETE and 5,500 GET requests per second per prefix
- **Cost-Effective**: Multiple storage classes, lifecycle policies
- **Security**: Encryption, access control, compliance
- **Integration**: Works with virtually all AWS services

### Use Cases
- Data lakes and big data analytics
- Backup and disaster recovery
- Archive (compliance, regulatory)
- Application hosting (static websites)
- Media hosting and distribution
- Software delivery
- Data archival (long-term retention)

## How S3 Works

### Core Concepts

**Buckets**:
- Container for objects
- Globally unique name (across all AWS accounts)
- Regional resource (data stored in specific region)
- Unlimited objects per bucket
- Naming: 3-63 chars, lowercase, no underscores, no IP format

**Objects**:
- Files stored in buckets
- Key: Full path (folder/subfolder/file.txt)
- Value: Content (max 5 TB)
- Metadata: Key-value pairs
- Version ID: If versioning enabled
- Max size per PUT: 5 GB (use multipart for larger)

**S3 URL Formats**:
```
Virtual-hosted style: https://bucket-name.s3.region.amazonaws.com/key
Path style (deprecated): https://s3.region.amazonaws.com/bucket-name/key
```

### Data Consistency Model

**Read-After-Write Consistency** (Strong Consistency since Dec 2020):
- PUT new object → immediately readable
- DELETE/PUT overwrite → immediately consistent
- LIST operations → immediately reflect changes
- No eventual consistency anymore

## S3 Storage Classes (Deep Dive)

### 1. S3 Standard
**What**: General-purpose storage

**Characteristics**:
- **Durability**: 11 9's (99.999999999%)
- **Availability**: 99.99%
- **AZs**: ≥3
- **Retrieval**: Immediate, no retrieval fee
- **Min Storage**: None
- **Min Duration**: None

**Pricing** (us-east-1):
- Storage: $0.023/GB-month (first 50 TB)
- PUT/POST: $0.005 per 1,000 requests
- GET: $0.0004 per 1,000 requests
- Data transfer out: $0.09/GB (after free tier)

**Use Cases**:
- Frequently accessed data
- Content distribution
- Big data analytics
- Mobile/gaming applications

**When to Use**:
- Default choice
- Data accessed weekly or more
- Low latency required

### 2. S3 Intelligent-Tiering
**What**: Automatically moves data between tiers based on access patterns

**Tiers**:
- **Frequent Access**: Automatically placed here initially
- **Infrequent Access**: Not accessed for 30 days
- **Archive Instant Access**: Not accessed for 90 days
- **Archive Access** (optional): Not accessed for 90-730 days
- **Deep Archive Access** (optional): Not accessed for 180-730 days

**Characteristics**:
- **Durability**: 11 9's
- **Availability**: 99.9%
- **AZs**: ≥3
- **Monitoring fee**: $0.0025 per 1,000 objects
- **No retrieval fees**
- **Min object size**: 128 KB (smaller billed at 128 KB)

**Pricing**:
- Frequent tier: $0.023/GB
- Infrequent tier: $0.0125/GB (46% savings)
- Archive Instant: $0.004/GB (83% savings)
- Archive Access: $0.0036/GB (84% savings)
- Deep Archive: $0.00099/GB (96% savings)

**Use Cases**:
- Unknown or changing access patterns
- Data lakes
- Long-lived data with unpredictable access

**When NOT to Use**:
- Small objects (<128 KB) - not cost effective
- Known access patterns (use specific class)
- Objects deleted quickly (<30 days)

### 3. S3 Standard-IA (Infrequent Access)
**What**: Less frequently accessed but requires rapid access when needed

**Characteristics**:
- **Durability**: 11 9's
- **Availability**: 99.9%
- **AZs**: ≥3
- **Min storage**: 128 KB
- **Min duration**: 30 days
- **Retrieval fee**: $0.01/GB

**Pricing**:
- Storage: $0.0125/GB-month (46% cheaper than Standard)
- PUT/POST: $0.01 per 1,000
- GET: $0.001 per 1,000
- Retrieval: $0.01/GB

**Use Cases**:
- Disaster recovery backups
- Long-term storage
- Older media files
- Infrequently accessed logs

**Cost Calculation**:
```
Scenario: 1 TB stored for 1 month, accessed once (10 GB download)

Standard-IA:
Storage: 1,000 GB × $0.0125 = $12.50
Retrieval: 10 GB × $0.01 = $0.10
Total: $12.60

Standard:
Storage: 1,000 GB × $0.023 = $23.00
Total: $23.00

Savings: $10.40/month (45%)
```

**When NOT to Use**:
- Frequent access (retrieval fees add up)
- Objects <128 KB
- Short-term storage (<30 days)

### 4. S3 One Zone-IA
**What**: Infrequently accessed data stored in single AZ

**Characteristics**:
- **Durability**: 11 9's (in that one AZ)
- **Availability**: 99.5%
- **AZs**: 1 (data lost if AZ destroyed)
- **Min storage**: 128 KB
- **Min duration**: 30 days
- **Retrieval fee**: $0.01/GB

**Pricing**:
- Storage: $0.01/GB-month (20% cheaper than Standard-IA)
- 56% cheaper than Standard

**Use Cases**:
- Secondary backup copies
- Reproducible data
- Cross-region replication destination

**When to Use**:
- Can recreate data if lost
- Cost savings more important than AZ resilience
- Not mission-critical data

**When NOT to Use**:
- Compliance requires multi-AZ
- Cannot afford to lose data if AZ fails
- Primary or only copy of data

### 5. S3 Glacier Instant Retrieval
**What**: Archive storage with millisecond retrieval

**Characteristics**:
- **Durability**: 11 9's
- **Availability**: 99.9%
- **AZs**: ≥3
- **Retrieval**: Milliseconds
- **Min storage**: 128 KB
- **Min duration**: 90 days
- **Retrieval fee**: $0.03/GB

**Pricing**:
- Storage: $0.004/GB-month (83% cheaper than Standard)
- Retrieval: $0.03/GB

**Use Cases**:
- Medical images
- News media archives
- Regulatory archives requiring instant access
- Backup files

**When to Use**:
- Accessed once per quarter or less
- Need immediate access when retrieved
- Long-term retention

**Cost Comparison** (1 TB, 1 year, 1 retrieval):
```
Glacier Instant Retrieval:
Storage: 1,000 × $0.004 × 12 = $48
Retrieval: 1,000 × $0.03 × 1 = $30
Total: $78

Standard:
Storage: 1,000 × $0.023 × 12 = $276
Total: $276

Savings: $198/year (72%)
```

### 6. S3 Glacier Flexible Retrieval (formerly Glacier)
**What**: Archive storage with retrieval in minutes to hours

**Characteristics**:
- **Durability**: 11 9's
- **Availability**: 99.99%
- **AZs**: ≥3
- **Min duration**: 90 days
- **Retrieval options**:
  - Expedited: 1-5 minutes ($0.03/GB + $10 per 1,000 requests)
  - Standard: 3-5 hours ($0.01/GB)
  - Bulk: 5-12 hours ($0.0025/GB)

**Pricing**:
- Storage: $0.0036/GB-month (84% cheaper than Standard)
- Upload: FREE
- Retrieval: See above

**Use Cases**:
- Long-term backups
- Regulatory archives
- Media archives (rarely accessed)
- Data that can wait hours for retrieval

**When to Use**:
- Accessed 1-2 times per year
- Can wait minutes/hours for retrieval
- Compliance retention

**Retrieval Cost Example** (100 GB):
```
Expedited: 100 × $0.03 = $3.00 (1-5 minutes)
Standard: 100 × $0.01 = $1.00 (3-5 hours)
Bulk: 100 × $0.0025 = $0.25 (5-12 hours)
```

### 7. S3 Glacier Deep Archive
**What**: Lowest cost storage for long-term retention

**Characteristics**:
- **Durability**: 11 9's
- **Availability**: 99.99%
- **AZs**: ≥3
- **Min duration**: 180 days
- **Retrieval options**:
  - Standard: 12 hours ($0.02/GB)
  - Bulk: 48 hours ($0.0025/GB)

**Pricing**:
- Storage: $0.00099/GB-month (96% cheaper than Standard)
- Cheapest storage in AWS

**Use Cases**:
- Regulatory compliance (7+ year retention)
- Financial records
- Healthcare records
- Media preservation
- Data that may never be retrieved

**Cost Example** (100 TB for 10 years):
```
Deep Archive:
100,000 GB × $0.00099 × 120 months = $11,880

Standard:
100,000 GB × $0.023 × 120 months = $276,000

Savings: $264,120 (96%)
```

**When to Use**:
- Long-term archival (7+ years)
- Compliance retention
- Can wait 12-48 hours for retrieval
- Rarely or never accessed

**When NOT to Use**:
- Need quick access
- Frequent retrieval
- Short-term storage (<180 days)

### 8. S3 on Outposts
**What**: S3 on your on-premises AWS Outposts

**Characteristics**:
- S3 API compatibility
- Local data residency
- Single storage class

**Use Cases**:
- On-premises data residency requirements
- Local data processing
- Hybrid cloud architectures

## Storage Class Comparison Table

| Class | Durability | Availability | AZs | Min Duration | Min Size | Retrieval Time | Storage Cost | Retrieval Fee |
|-------|-----------|--------------|-----|--------------|----------|----------------|--------------|---------------|
| Standard | 11 9's | 99.99% | ≥3 | None | None | Instant | $0.023/GB | None |
| Intelligent-Tiering | 11 9's | 99.9% | ≥3 | None | 128KB | Varies | $0.023-0.00099/GB | None |
| Standard-IA | 11 9's | 99.9% | ≥3 | 30 days | 128KB | Instant | $0.0125/GB | $0.01/GB |
| One Zone-IA | 11 9's* | 99.5% | 1 | 30 days | 128KB | Instant | $0.01/GB | $0.01/GB |
| Glacier Instant | 11 9's | 99.9% | ≥3 | 90 days | 128KB | Milliseconds | $0.004/GB | $0.03/GB |
| Glacier Flexible | 11 9's | 99.99% | ≥3 | 90 days | None | Minutes-Hours | $0.0036/GB | $0.0025-0.03/GB |
| Glacier Deep | 11 9's | 99.99% | ≥3 | 180 days | None | Hours | $0.00099/GB | $0.0025-0.02/GB |

*Within that AZ

## S3 Lifecycle Policies

### What Are Lifecycle Policies?

**Purpose**: Automatically transition or delete objects based on age

**Actions**:
1. **Transition**: Move to different storage class
2. **Expiration**: Delete objects

### Transition Rules

**Allowed Transitions**:
```
Standard → Standard-IA (after 30 days)
         → Intelligent-Tiering (any time)
         → One Zone-IA (after 30 days)
         → Glacier Instant (after 0 days)
         → Glacier Flexible (after 0 days)
         → Glacier Deep Archive (after 0 days)

Standard-IA → Glacier Instant (after 30 days from creation)
             → Glacier Flexible (after 30 days from creation)
             → Glacier Deep Archive (after 30 days from creation)

Glacier Instant → Glacier Flexible (after 90 days from creation)
                 → Glacier Deep Archive (after 90 days from creation)

Glacier Flexible → Glacier Deep Archive (after 90 days from creation)
```

**Important Constraints**:
- Must wait 30 days before transitioning to IA classes
- Cannot transition from Glacier classes to Standard or IA

### Example Lifecycle Policies

**Example 1: Log Archival**
```json
{
  "Rules": [{
    "Id": "LogRetention",
    "Status": "Enabled",
    "Filter": {
      "Prefix": "logs/"
    },
    "Transitions": [
      {
        "Days": 30,
        "StorageClass": "STANDARD_IA"
      },
      {
        "Days": 90,
        "StorageClass": "GLACIER_IR"
      },
      {
        "Days": 365,
        "StorageClass": "DEEP_ARCHIVE"
      }
    ],
    "Expiration": {
      "Days": 2555
    }
  }]
}
```

**Timeline**:
- Day 0-30: S3 Standard ($0.023/GB)
- Day 31-90: Standard-IA ($0.0125/GB)
- Day 91-365: Glacier Instant ($0.004/GB)
- Day 366-2555: Deep Archive ($0.00099/GB)
- Day 2556: Deleted (7-year retention)

**Example 2: Multi-part Upload Cleanup**
```json
{
  "Rules": [{
    "Id": "CleanupIncompleteUploads",
    "Status": "Enabled",
    "Filter": {},
    "AbortIncompleteMultipartUpload": {
      "DaysAfterInitiation": 7
    }
  }]
}
```

**Example 3: Version Cleanup**
```json
{
  "Rules": [{
    "Id": "VersionRetention",
    "Status": "Enabled",
    "Filter": {},
    "NoncurrentVersionTransitions": [
      {
        "NoncurrentDays": 30,
        "StorageClass": "STANDARD_IA"
      },
      {
        "NoncurrentDays": 90,
        "StorageClass": "GLACIER"
      }
    ],
    "NoncurrentVersionExpiration": {
      "NoncurrentDays": 365
    }
  }]
}
```

### Cost Optimization with Lifecycle

**Scenario**: 10 TB data, growing 1 TB/month

**Without Lifecycle** (all Standard):
- Month 1: 10 TB × $0.023 = $230
- Month 12: 22 TB × $0.023 = $506
- Annual: ~$4,400

**With Lifecycle**:
- Current month: Standard ($0.023/GB)
- 1-3 months old: Standard-IA ($0.0125/GB)
- 3+ months old: Glacier Flexible ($0.0036/GB)
- Month 12 cost: ~$180
- Annual: ~$2,200
- **Savings: 50%**

## S3 Versioning

### What is Versioning?

**Purpose**: Keep multiple variants of an object

**Behavior**:
- New version on every modification
- DELETE creates delete marker (can restore)
- Previous versions preserved

**States**:
- **Unversioned** (default): No versioning
- **Enabled**: Versioning on, cannot disable (only suspend)
- **Suspended**: New objects have null version ID

### How Versioning Works

**Upload same key multiple times**:
```
PUT my-file.txt (content: "v1") → Version ID: abc123
PUT my-file.txt (content: "v2") → Version ID: def456 (latest)
PUT my-file.txt (content: "v3") → Version ID: ghi789 (latest)

GET my-file.txt → Returns ghi789 (latest version)
GET my-file.txt?versionId=abc123 → Returns abc123
```

**Delete behavior**:
```
DELETE my-file.txt → Creates delete marker (jkl012)
GET my-file.txt → 404 Not Found

DELETE my-file.txt?versionId=jkl012 → Deletes marker, restores file
GET my-file.txt → Returns ghi789

DELETE my-file.txt?versionId=ghi789 → Permanently deletes that version
```

### Use Cases

**1. Accidental Deletion Protection**:
- User deletes file → create delete marker
- Restore by deleting the marker

**2. Application Rollback**:
- Deploy code → new version
- Bug found → retrieve previous version

**3. Compliance**:
- Audit trail of all changes
- Cannot modify/delete without permissions

**4. Ransomware Protection**:
- Malicious encryption → new versions
- Roll back to previous versions
- Combine with MFA Delete

### Cost Implications

**Each version is billed**:
```
File: 1 GB
v1: 1 GB
v2: 1 GB (modified)
v3: 1 GB (modified)

Storage cost: 3 GB (not 1 GB)
```

**Cost Optimization**:
```json
{
  "Rules": [{
    "NoncurrentVersionExpiration": {
      "NoncurrentDays": 30
    }
  }]
}
```
Deletes non-current versions after 30 days

### MFA Delete

**What**: Require MFA to delete versions or suspend versioning

**Enable** (only via CLI/API, not Console):
```bash
aws s3api put-bucket-versioning \
  --bucket my-bucket \
  --versioning-configuration Status=Enabled,MFADelete=Enabled \
  --mfa "arn:aws:iam::123456789012:mfa/user 123456"
```

**When to Use**:
- Highly sensitive data
- Compliance requirements
- Protection against malicious deletion

## S3 Replication

### Types of Replication

**1. Cross-Region Replication (CRR)**:
- Source and destination in different regions
- Use cases: Compliance, lower latency, disaster recovery

**2. Same-Region Replication (SRR)**:
- Source and destination in same region
- Use cases: Log aggregation, prod/test sync, compliance

### How Replication Works

**Requirements**:
- Versioning enabled on both buckets
- IAM role with permissions
- Can replicate across accounts

**What is Replicated**:
- New objects (after enabling replication)
- Metadata and ACLs
- Object tags
- S3 Object Lock information

**What is NOT Replicated** (by default):
- Existing objects (need S3 Batch Replication)
- Objects from another replication
- Delete markers (optional)
- Objects encrypted with SSE-C
- Lifecycle actions

### Replication Configuration

**Basic Setup**:
```json
{
  "Role": "arn:aws:iam::123456789012:role/replication-role",
  "Rules": [{
    "Status": "Enabled",
    "Priority": 1,
    "Filter": {},
    "Destination": {
      "Bucket": "arn:aws:s3:::destination-bucket",
      "ReplicationTime": {
        "Status": "Enabled",
        "Time": {
          "Minutes": 15
        }
      },
      "Metrics": {
        "Status": "Enabled"
      }
    },
    "DeleteMarkerReplication": {
      "Status": "Enabled"
    }
  }]
}
```

**Advanced Features**:

**Replication Time Control (RTC)**:
- 99.99% of objects replicated within 15 minutes
- SLA-backed
- Additional cost: $0.015/GB

**Batch Replication**:
- Replicate existing objects
- One-time operation
- Use S3 Batch Operations

**Replica Modification Sync**:
- Replicate metadata changes
- Replicate ACL changes
- Replicate tags

### Use Case Examples

**Example 1: Disaster Recovery**
```
Production (us-east-1) → CRR → DR (us-west-2)
- RTC enabled (15-min RPO)
- Delete marker replication
- Encrypted at destination
```

**Cost** (1 TB/month, 100 GB changes):
- Storage in DR: 1,000 GB × $0.023 = $23
- Replication: 100 GB × $0.02 = $2
- RTC: 100 GB × $0.015 = $1.50
- Total: $26.50/month

**Example 2: Multi-Region Access**
```
US users → S3 (us-east-1)
EU users → S3 (eu-west-1)
           ↑ CRR ↓
```
- Bi-directional replication
- Lower latency for users
- Cross-region data residency

**Example 3: Log Aggregation**
```
Account A (logs/) → SRR → Central bucket
Account B (logs/) → SRR → Central bucket
Account C (logs/) → SRR → Central bucket
```
- Centralized log analysis
- Cross-account replication
- Same region (lower cost)

### Replication vs Backup

| Feature | Replication | Backup |
|---------|-------------|--------|
| Purpose | Real-time copy | Point-in-time restore |
| Frequency | Continuous | Scheduled |
| Deletion | Replicated | Not affected |
| Cost | Ongoing storage × 2 | Incremental |
| Recovery | Immediate switch | Restore process |

## S3 Security (Deep Dive)

### Encryption

**Encryption at Rest**:

**1. Server-Side Encryption with S3 Managed Keys (SSE-S3)**:
- **What**: AWS manages keys
- **Encryption**: AES-256
- **Header**: `x-amz-server-side-encryption: AES256`
- **Cost**: No additional cost
- **Use**: Default choice

**2. Server-Side Encryption with KMS (SSE-KMS)**:
- **What**: AWS KMS manages keys
- **Benefits**: Audit trail, key rotation, access control
- **Header**: `x-amz-server-side-encryption: aws:kms`
- **Cost**: KMS API calls ($0.03 per 10,000 requests)
- **Limit**: KMS throttling (5,500-30,000 requests/sec per region)
- **Use**: Compliance, audit requirements

**3. Server-Side Encryption with Customer Keys (SSE-C)**:
- **What**: You provide encryption keys
- **Keys**: Sent in HTTPS header
- **AWS**: Doesn't store keys
- **Responsibility**: Key management is yours
- **Use**: Own key management system

**4. Client-Side Encryption**:
- **What**: Encrypt before uploading
- **Tools**: AWS Encryption SDK, S3 Encryption Client
- **Responsibility**: Full control and management
- **Use**: Maximum security control

**Encryption in Transit**:
- HTTPS/TLS (SSL)
- Enforce with bucket policy:
```json
{
  "Effect": "Deny",
  "Principal": "*",
  "Action": "s3:*",
  "Resource": "arn:aws:s3:::my-bucket/*",
  "Condition": {
    "Bool": {
      "aws:SecureTransport": "false"
    }
  }
}
```

**Default Encryption**:
- Bucket-level setting
- Encrypts all new objects
- SSE-S3 or SSE-KMS
- Doesn't affect existing objects

### Access Control

**Levels of Control**:
1. IAM Policies (user/role)
2. Bucket Policies (bucket-level)
3. ACLs (object/bucket level) - legacy
4. S3 Access Points
5. VPC Endpoints

**1. IAM Policies**:
```json
{
  "Effect": "Allow",
  "Action": [
    "s3:GetObject",
    "s3:PutObject"
  ],
  "Resource": "arn:aws:s3:::my-bucket/*"
}
```
- Attached to users/roles/groups
- Controls what principal can do

**2. Bucket Policies**:
```json
{
  "Version": "2012-10-17",
  "Statement": [{
    "Sid": "PublicRead",
    "Effect": "Allow",
    "Principal": "*",
    "Action": "s3:GetObject",
    "Resource": "arn:aws:s3:::my-bucket/*"
  }]
}
```
- JSON-based
- Controls access to bucket
- Can grant cross-account access
- Can enforce encryption

**IAM vs Bucket Policy**:
- **IAM**: User can access (attach to user)
- **Bucket Policy**: Who can access bucket (attach to bucket)
- **Evaluation**: Union of both (either allows → allowed)

**3. S3 Access Control Lists (ACLs)**:
- Legacy (use bucket policies instead)
- Grantee-level permissions
- Use cases: CloudFront origin access

**4. S3 Access Points**:
```
Bucket: my-data-bucket
├── Access Point: finance-ap (prefix: /finance/)
├── Access Point: hr-ap (prefix: /hr/)
└── Access Point: analytics-ap (read-only)
```

- Dedicated hostname per access point
- Individual policies per access point
- Simplify complex bucket policies
- Can restrict to VPC

**Example**:
```json
{
  "Name": "finance-access-point",
  "Bucket": "my-data-bucket",
  "Policy": {
    "Statement": [{
      "Effect": "Allow",
      "Principal": {"AWS": "arn:aws:iam::123456789012:role/FinanceRole"},
      "Action": ["s3:GetObject", "s3:PutObject"],
      "Resource": "arn:aws:s3:us-east-1:123456789012:accesspoint/finance-access-point/object/finance/*"
    }]
  }
}
```

### Block Public Access

**4 Settings**:
1. **BlockPublicAcls**: Block public ACLs on new objects
2. **IgnorePublicAcls**: Ignore existing public ACLs
3. **BlockPublicPolicy**: Block public bucket policies
4. **RestrictPublicBuckets**: Restrict access to bucket with public policies

**Levels**:
- Account-level (all buckets)
- Bucket-level (specific bucket)

**Best Practice**: Enable all 4 unless you need public access

### Pre-Signed URLs

**What**: Temporary URL for private objects

**Use Cases**:
- Allow user to download private file
- Allow user to upload to specific key
- Time-limited access

**Example (SDK)**:
```python
import boto3
from botocore.client import Config

s3 = boto3.client('s3', config=Config(signature_version='s3v4'))

# Generate pre-signed URL (valid for 1 hour)
url = s3.generate_presigned_url(
    'get_object',
    Params={'Bucket': 'my-bucket', 'Key': 'private-file.pdf'},
    ExpiresIn=3600
)
```

**URL Format**:
```
https://my-bucket.s3.amazonaws.com/private-file.pdf
?X-Amz-Algorithm=AWS4-HMAC-SHA256
&X-Amz-Credential=...
&X-Amz-Date=20260131T120000Z
&X-Amz-Expires=3600
&X-Amz-SignedHeaders=host
&X-Amz-Signature=...
```

**Security**:
- Uses signer's permissions at generation time
- If permissions revoked, URL still works until expiry
- Max expiry: 7 days (STS), 12 hours (IAM user)

### S3 Object Lock

**What**: Write-Once-Read-Many (WORM) model

**Use Cases**:
- Regulatory compliance
- Prevent deletion/modification
- Ransomware protection

**Modes**:

**1. Governance Mode**:
- Users can't overwrite/delete
- Special permissions can bypass (`s3:BypassGovernanceRetention`)
- Use: Internal compliance

**2. Compliance Mode**:
- No one can delete (not even root)
- Retention period cannot be shortened
- Use: Regulatory requirements (SEC, FINRA)

**Retention Periods**:
- Fixed retention period
- Object locked until date
- Can extend, cannot shorten

**Legal Hold**:
- Indefinite lock
- No retention period
- On/off toggle
- Requires `s3:PutObjectLegalHold` permission

**Configuration**:
```json
{
  "ObjectLockEnabled": "Enabled",
  "Rule": {
    "DefaultRetention": {
      "Mode": "COMPLIANCE",
      "Days": 365
    }
  }
}
```

**Requirements**:
- Versioning must be enabled
- Can only enable on bucket creation
- Cannot disable after enabling

### S3 Access Logs

**What**: Log all requests to bucket

**Configuration**:
```
Source bucket: my-app-bucket
Target bucket: my-logs-bucket
Prefix: app-logs/
```

**Log Format**:
```
79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be my-app-bucket [31/Jan/2026:12:00:00 +0000] 192.0.2.3 arn:aws:iam::123456789012:user/alice 3E57427F3EXAMPLE REST.GET.OBJECT photo.jpg "GET /my-app-bucket/photo.jpg HTTP/1.1" 200 - 2662992 - 70 10 "-" "curl/7.15.1" -
```

**Contains**:
- Requester
- Bucket/object
- Action
- Response code
- Error code
- Bytes sent

**Use Cases**:
- Security audits
- Access pattern analysis
- Compliance
- Troubleshooting

**Best Practices**:
- Don't log to same bucket (loop)
- Lifecycle policy on log bucket
- Encrypt logs

**Cost**: Free feature, pay for storage of logs

### S3 Inventory

**What**: Scheduled report of objects and metadata

**Frequency**: Daily or Weekly

**Output**: CSV, ORC, or Parquet

**Contents**:
- Object key
- Size
- Last modified date
- Storage class
- Encryption status
- Replication status
- Metadata

**Use Cases**:
- Audit encryption status
- List objects (faster than LIST API)
- Business intelligence

**Configuration**:
```json
{
  "Destination": {
    "S3BucketDestination": {
      "Bucket": "arn:aws:s3:::inventory-bucket",
      "Format": "CSV",
      "Prefix": "inventory-reports/"
    }
  },
  "IsEnabled": true,
  "Filter": {
    "Prefix": "data/"
  },
  "Schedule": {
    "Frequency": "Daily"
  },
  "OptionalFields": [
    "Size", "LastModifiedDate", "StorageClass", "ETag"
  ]
}
```

**vs List API**:
- Inventory: Batch, scheduled, cost-effective for billions of objects
- List: Real-time, immediate, expensive for large datasets

## S3 Performance Optimization

### Request Rate Performance

**Per Prefix**:
- 3,500 PUT/COPY/POST/DELETE per second
- 5,500 GET/HEAD per second

**Scaling**:
- Use multiple prefixes
- Example: 10 prefixes = 35,000 PUT/s, 55,000 GET/s

**Prefix Example**:
```
bucket/folder1/file1.txt  (prefix: folder1/)
bucket/folder2/file2.txt  (prefix: folder2/)
bucket/f1/f2/file3.txt    (prefix: f1/f2/)
```

### Transfer Acceleration

**What**: Upload to edge location, then AWS network to bucket

**How it Works**:
```
User (Tokyo) → Edge (Tokyo) → AWS Network → Bucket (us-east-1)
vs
User (Tokyo) → Internet → Bucket (us-east-1)
```

**Speed Improvement**: 50-500% faster for distant users

**Endpoint**:
```
Normal: my-bucket.s3.amazonaws.com
Accelerated: my-bucket.s3-accelerate.amazonaws.com
```

**Cost**: $0.04-0.08 per GB (in addition to normal charges)

**When to Use**:
- Uploading from globally distributed users
- Files > 1 GB
- High throughput required

**When NOT to Use**:
- Users in same region as bucket
- Small files
- Cost-sensitive

**Speed Comparison Tool**:
https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com

### Multipart Upload

**What**: Upload object in parts

**Benefits**:
- Parallel uploads (faster)
- Resume failed uploads
- Upload before knowing total size

**When to Use**:
- **Must use** for objects > 5 GB
- **Recommended** for objects > 100 MB

**Process**:
1. Initiate multipart upload
2. Upload parts (1-10,000 parts)
3. Complete multipart upload (S3 reassembles)

**Part Size**: 5 MB - 5 GB (except last part)

**Example** (AWS CLI):
```bash
# Initiate
aws s3api create-multipart-upload --bucket my-bucket --key large-file.zip

# Upload parts
aws s3api upload-part --bucket my-bucket --key large-file.zip --part-number 1 --body part1.bin --upload-id xyz

# Complete
aws s3api complete-multipart-upload --bucket my-bucket --key large-file.zip --upload-id xyz --multipart-upload file://parts.json
```

**Lifecycle Cleanup**:
```json
{
  "AbortIncompleteMultipartUpload": {
    "DaysAfterInitiation": 7
  }
}
```

**Performance**:
- 100 MB file, 10 MB parts = 10 parallel uploads
- 1 GB file, 100 MB parts = 10 parallel uploads at 10x speed

### S3 Transfer Manager

**What**: High-level SDK abstraction

**Features**:
- Automatic multipart upload
- Retry logic
- Parallel downloads
- Pause/resume

**Languages**: Java, Python, .NET, Node.js

**Example** (Python):
```python
from boto3.s3.transfer import TransferConfig
import boto3

s3 = boto3.client('s3')

config = TransferConfig(
    multipart_threshold=1024 * 25,  # 25 MB
    max_concurrency=10,
    multipart_chunksize=1024 * 25,
    use_threads=True
)

s3.upload_file('large-file.zip', 'my-bucket', 'large-file.zip', Config=config)
```

### Byte-Range Fetches

**What**: Retrieve specific byte range of object

**Use Cases**:
- Download specific part of file
- Parallel downloads
- Resume failed downloads
- Read file headers only

**Example**:
```bash
# Get first 1000 bytes
aws s3api get-object --bucket my-bucket --key large-file.bin --range bytes=0-999 part1.bin

# Get bytes 1000-1999
aws s3api get-object --bucket my-bucket --key large-file.bin --range bytes=1000-1999 part2.bin
```

**Performance**:
- 1 GB file, 10 parallel range fetches = 10x speed
- Resilience: Failure of one range doesn't affect others

### S3 Select and Glacier Select

**What**: SQL query on object without retrieving full object

**Supported Formats**: CSV, JSON, Parquet

**Benefits**:
- Retrieve subset of data
- Reduce data transfer (up to 80%)
- Reduce cost
- Faster (less data transferred)

**Example**:
```python
response = s3.select_object_content(
    Bucket='my-bucket',
    Key='data.csv',
    Expression="SELECT * FROM S3Object WHERE age > 30",
    ExpressionType='SQL',
    InputSerialization={'CSV': {'FileHeaderInfo': 'Use'}},
    OutputSerialization={'JSON': {}}
)
```

**Use Cases**:
- Log analysis
- Query CSV/JSON data
- Filter large datasets
- Reduce Lambda processing time

**Cost**:
- Scanned: $0.002 per GB
- Returned: $0.0007 per GB
- Still cheaper than downloading full object

**vs Athena**:
- S3 Select: Single object, simple queries
- Athena: Multiple objects, complex queries, joins

## S3 Event Notifications

### What Are Event Notifications?

**Events**:
- Object created (Put, Post, Copy, CompleteMultipartUpload)
- Object removed (Delete, DeleteMarkerCreated)
- Object restored (from Glacier)
- Replication events (missed, replicated, etc.)
- Reduced Redundancy Storage (RRS) object lost

**Destinations**:
1. SNS (Simple Notification Service)
2. SQS (Simple Queue Service)
3. Lambda functions
4. EventBridge (most flexible)

### Configuration Examples

**Example 1: Lambda on Upload**
```json
{
  "LambdaFunctionConfigurations": [{
    "LambdaFunctionArn": "arn:aws:lambda:us-east-1:123456789012:function:ProcessImage",
    "Events": ["s3:ObjectCreated:*"],
    "Filter": {
      "Key": {
        "FilterRules": [{
          "Name": "prefix",
          "Value": "images/"
        }, {
          "Name": "suffix",
          "Value": ".jpg"
        }]
      }
    }
  }]
}
```

**Example 2: SQS for Processing**
```json
{
  "QueueConfigurations": [{
    "QueueArn": "arn:aws:sqs:us-east-1:123456789012:file-processing-queue",
    "Events": ["s3:ObjectCreated:*"],
    "Filter": {
      "Key": {
        "FilterRules": [{
          "Name": "prefix",
          "Value": "uploads/"
        }]
      }
    }
  }]
}
```

**Example 3: EventBridge (Advanced)**
```
S3 Event → EventBridge → Multiple targets:
                         ├→ Lambda (image processing)
                         ├→ StepFunctions (workflow)
                         ├→ SNS (notification)
                         └→ CloudWatch Logs
```

**EventBridge Benefits**:
- More targets (18+ services)
- Advanced filtering
- Archive and replay
- Cross-account delivery

### Use Cases

**1. Image Processing**:
```
Upload image.jpg → S3 Event → Lambda → Create thumbnail → Store in S3
```

**2. Data Lake Ingestion**:
```
Upload data.csv → S3 Event → SQS → Lambda → Process → Store in DB
```

**3. Log Processing**:
```
Application logs → S3 → EventBridge → Firehose → OpenSearch
```

**4. Video Transcoding**:
```
Upload video.mp4 → S3 Event → Lambda → Start MediaConvert job → Output to S3
```

**Important**: 
- Events delivered in seconds (typically)
- If two writes to same key rapidly, may only receive one notification
- Events not guaranteed to arrive in order

## S3 Static Website Hosting

### Configuration

**Enable Website Hosting**:
- Index document: `index.html`
- Error document: `error.html`
- Redirect rules (optional)

**Endpoint Format**:
```
http://bucket-name.s3-website-region.amazonaws.com
http://bucket-name.s3-website.region.amazonaws.com
```

**Requirements**:
- Bucket must be public (or use bucket policy)
- Objects must be publicly readable

**Bucket Policy for Public Access**:
```json
{
  "Statement": [{
    "Effect": "Allow",
    "Principal": "*",
    "Action": "s3:GetObject",
    "Resource": "arn:aws:s3:::my-website/*"
  }]
}
```

### Use Cases

- Static websites (HTML, CSS, JS)
- Single Page Applications (React, Vue, Angular)
- Redirects
- Marketing pages

### With CloudFront

**Architecture**:
```
User → CloudFront → S3 (Origin)
```

**Benefits**:
- HTTPS support (S3 website endpoints don't support HTTPS)
- Custom domain with ACM certificate
- Caching at edge locations
- DDoS protection
- Geo-restriction

**Cost Comparison** (1 TB delivered):
- S3 Direct: $90 (data transfer)
- CloudFront: $85 (data transfer) + caching benefits

### Redirects

**Redirect All Requests**:
```json
{
  "RedirectAllRequestsTo": {
    "HostName": "www.example.com",
    "Protocol": "https"
  }
}
```

**Routing Rules**:
```json
{
  "RoutingRules": [{
    "Condition": {
      "KeyPrefixEquals": "docs/"
    },
    "Redirect": {
      "HostName": "documentation.example.com"
    }
  }]
}
```

## S3 Batch Operations

### What is S3 Batch Operations?

**Purpose**: Perform operations on billions of objects

**Operations**:
- Copy objects
- Invoke Lambda function
- Restore from Glacier
- Replace ACL
- Replace tags
- Delete Object Lock retention
- Put Object Lock retention

### How It Works

1. Create inventory or CSV of objects
2. Create Batch Operations job
3. Job executes operations
4. Completion report generated

**Example**: Encrypt All Objects
```json
{
  "Operation": {
    "S3PutObjectCopy": {
      "TargetResource": "arn:aws:s3:::my-bucket",
      "StorageClass": "STANDARD",
      "ServerSideEncryption": "aws:kms",
      "SSEKMSKeyId": "arn:aws:kms:us-east-1:123456789012:key/abc123"
    }
  },
  "Manifest": {
    "Spec": {"Format": "S3InventoryReport_CSV_20161130"},
    "Location": {
      "ObjectArn": "arn:aws:s3:::inventory-bucket/manifest.json",
      "ETag": "abc123"
    }
  }
}
```

**Use Cases**:
- One-time migration to new storage class
- Tag all objects
- Copy to another account
- Invoke Lambda on all objects (e.g., virus scan)
- Restore archive

**Cost**: $0.25 per million object operations

## S3 Performance Best Practices (Exam Focus)

### Summary Table

| Requirement | Solution |
|-------------|----------|
| High request rate | Use multiple prefixes (3,500 PUT/5,500 GET per prefix) |
| Fast uploads from distant users | S3 Transfer Acceleration |
| Large files (>100 MB) | Multipart Upload |
| Fast downloads | CloudFront, byte-range fetches, multiple prefixes |
| Query data without full download | S3 Select |
| Billions of objects to process | S3 Batch Operations |
| Consistent read | Built-in (strong consistency) |
| Low latency for users | CloudFront CDN |

## S3 vs Alternatives

### S3 vs EBS
| Feature | S3 | EBS |
|---------|----|----|
| Type | Object storage | Block storage |
| Access | HTTP API | File system |
| Durability | 11 9's | 99.8-99.9% |
| Scalability | Unlimited | Single volume up to 64 TB |
| Use Case | Shared storage, archives | EC2 boot volumes, databases |
| Cost | $0.023/GB | $0.08-0.125/GB |

### S3 vs EFS
| Feature | S3 | EFS |
|---------|----|----|
| Type | Object storage | File storage (NFS) |
| Access | HTTP API | File system mount |
| Performance | 5,500 GET/s per prefix | Depends on mode |
| Use Case | Unstructured data | Shared file system |
| Cost | $0.023/GB | $0.30/GB |

### S3 vs Glacier
- Glacier is S3 storage class (not separate service)
- Use Glacier classes for archival
- Use S3 Standard for frequent access

## Real-World Scenarios (Exam Focused)

### Scenario 1: Data Lake for Analytics
**Requirements**:
- Store petabytes of data
- Query with SQL
- Cost-effective
- Multiple teams access

**Solution**:
```
Data Sources → S3 (Data Lake)
├── Raw data: Intelligent-Tiering
├── Processed data: Standard
└── Archives: Glacier Flexible

Access:
├── Athena (SQL queries)
├── EMR (big data processing)
├── Glue (ETL)
└── Lake Formation (governance)

Security:
├── Encryption: SSE-KMS
├── Access: S3 Access Points per team
└── Audit: S3 Access Logs + CloudTrail
```

**Cost** (1 PB, 10% accessed monthly):
- Storage: $18,000/month (Intelligent-Tiering)
- Queries: $5,000/month (Athena)
- Total: $23,000/month

### Scenario 2: Global Media Distribution
**Requirements**:
- Video files (100 GB each)
- Users worldwide
- Low latency
- HTTPS

**Solution**:
```
Upload: Content Team → S3 Transfer Acceleration → S3 (us-east-1)
Distribution: S3 → CloudFront (global edge locations) → Users
Storage Classes:
├── Recent videos: S3 Standard
├── 1-year old: Standard-IA
└── 3+ years: Glacier Flexible
```

**Cost** (10 TB stored, 50 TB delivered/month):
- Storage: $230/month
- CloudFront: $4,250/month
- Transfer Acceleration: $200/month
- Total: $4,680/month (vs $7,000 without optimization)

### Scenario 3: Compliance Archival
**Requirements**:
- 7-year retention
- Cannot delete
- Audit trail
- Encryption

**Solution**:
```
Upload → S3
├── Versioning: Enabled
├── Object Lock: Compliance mode, 7 years
├── Encryption: SSE-KMS
├── Lifecycle: Transition to Deep Archive after 30 days
├── MFA Delete: Enabled
└── Logging: Access logs + CloudTrail

Storage Classes:
├── Day 0-30: Standard ($0.023/GB)
└── Day 31-2555: Deep Archive ($0.00099/GB)
```

**Cost** (100 TB, 7 years):
- Year 1: (30 days × $2,300) + (335 days × $99) = $3,400
- Year 2-7: $1,188/year
- Total 7-year: $10,528 (vs $193,200 if kept in Standard)
- **Savings: 94.5%**

### Scenario 4: Backup and DR
**Requirements**:
- Primary: us-east-1
- DR: us-west-2
- RPO: 1 hour
- Encryption

**Solution**:
```
Production DB → Backup → S3 (us-east-1)
                          ↓ CRR with RTC
                       S3 (us-west-2)

Configuration:
├── Versioning: Enabled
├── Replication: RTC (15-min)
├── Encryption: SSE-KMS
├── Lifecycle: 
│   ├── Current: Standard
│   ├── 30 days: Standard-IA
│   └── 90 days: Glacier Flexible
└── Expiration: 365 days
```

**Cost** (1 TB backups/day, 30-day retention):
- Storage (primary): $345/month
- Storage (DR): $345/month
- Replication: $600/month
- Total: $1,290/month

### Scenario 5: Serverless Web Application
**Requirements**:
- Static frontend
- Custom domain
- HTTPS
- API backend

**Solution**:
```
www.example.com → Route 53
                    ↓
                 CloudFront (HTTPS with ACM)
                    ↓
   ┌────────────────┴────────────────┐
   ↓                                 ↓
S3 (static files)              API Gateway → Lambda
```

**Configuration**:
```
S3 Bucket:
├── index.html, app.js, styles.css
├── Static website hosting: Disabled
├── Bucket Policy: Allow CloudFront only (OAI)
└── Storage Class: Standard

CloudFront:
├── Origins: S3 (static), API Gateway (dynamic)
├── Behaviors: /api/* → API Gateway, /* → S3
├── SSL: ACM certificate
└── Caching: Static (1 day), API (no cache)
```

**Cost** (10 GB storage, 100 GB transfer/month):
- S3: $0.23/month
- CloudFront: $8.50/month
- Route 53: $0.50/month
- Lambda: $5/month
- Total: $14.23/month

## Exam Tips (SAP-C02 Specific)

### Storage Class Decision Tree
```
Is data frequently accessed (weekly+)?
├─ YES: S3 Standard
└─ NO: How often accessed?
    ├─ Monthly: Standard-IA or Intelligent-Tiering
    ├─ Quarterly: Glacier Instant Retrieval
    ├─ Yearly: Glacier Flexible Retrieval
    └─ Rarely/Never: Glacier Deep Archive

Can you lose data if AZ fails?
├─ NO: Use multi-AZ (Standard, Standard-IA, Glacier)
└─ YES: One Zone-IA (if cost critical)
```

### Common Exam Scenarios

**"Minimize cost"**:
- Use Intelligent-Tiering (unknown patterns)
- Use lifecycle policies
- Use Glacier for archives
- Multipart upload (no extra cost, faster)

**"Encryption compliance"**:
- SSE-KMS (audit trail)
- Bucket policy to enforce encryption
- Default encryption on bucket

**"High availability"**:
- Multi-region with CRR
- CloudFront for caching
- Versioning for data protection

**"Cannot delete for X years"**:
- S3 Object Lock (Compliance mode)
- MFA Delete
- Versioning

**"Fast upload from global users"**:
- S3 Transfer Acceleration
- CloudFront signed URLs for uploads

**"Query large dataset without downloading"**:
- S3 Select (single object)
- Athena (multiple objects, complex queries)

**"Billions of objects to process"**:
- S3 Batch Operations
- S3 Inventory (list objects)

### Key Differentiation Points

**Replication**:
- CRR: Different regions (compliance, DR)
- SRR: Same region (log aggregation, test/prod)

**Encryption**:
- SSE-S3: AWS managed, no audit
- SSE-KMS: Audit trail, key rotation, access control
- SSE-C: You manage keys
- Client-side: Maximum control

**Consistency**:
- Strong consistency (no eventual)
- Read-after-write for all operations

**Access Control**:
- IAM: User-based permissions
- Bucket Policy: Resource-based, cross-account
- ACL: Legacy (avoid)
- Access Points: Complex multi-team access

### Common Traps
- **Glacier is NOT a separate service** (it's S3 storage class)
- **Cannot transition from Glacier back to Standard** (lifecycle only goes one way to colder tiers)
- **Versioning cannot be disabled** (only suspended)
- **Object Lock requires versioning**
- **Min duration charges** (IA: 30 days, Glacier Instant: 90 days, Deep Archive: 180 days)

This comprehensive guide covers S3 from basic concepts to advanced architectures. Focus on storage class selection, cost optimization, security, and performance for the SAP-C02 exam.
